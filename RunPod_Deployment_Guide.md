# RunPod è¬äººç´š Serverless vLLM æž¶è¨­æŒ‡å—

é€™ä»½æŒ‡å—æ˜¯å°ˆç‚ºæ‰¿å—**æ•¸åƒäººåŒæ™‚åœ¨ç·š**çš„é«˜æµé‡éœ€æ±‚æ‰€è¨­è¨ˆçš„ã€‚
æˆ‘å€‘ä½¿ç”¨ **vLLM (Versatile Large Language Model)** å¼•æ“Žï¼Œå®ƒæ˜¯ç›®å‰æ¥­ç•ŒæŽ¨è«–é€Ÿåº¦æœ€å¿«ã€åžåé‡ (Throughput) æœ€é«˜çš„é¸æ“‡ã€‚

---

## ðŸš€ æž¶æ§‹ç¸½è¦½
- **å¹³å°**: RunPod Serverless
- **å¼•æ“Ž**: vLLM (OpenAI Compatible)
- **æ¨¡åž‹**: Mistral-7B-Instruct-v0.2-AWQ (é€Ÿåº¦å„ªåŒ–ç‰ˆ) æˆ–æ˜¯ Llama-3-8B-Instruct
- **æˆæœ¬**: ä¾ä½¿ç”¨é‡è¨ˆè²» (é–’ç½®æ™‚å¯é™ç‚º $0)

---

## æ­¥é©Ÿä¸€ï¼šè¨­å®šæ¨¡æ¿ (Templates)

1. ç™»å…¥ [RunPod Console](https://www.runpod.io/console/serverless)ã€‚
2. é»žé¸å·¦å´ **Serverless** -> **My Templates** -> **New Template**ã€‚
3. å¡«å¯«ä»¥ä¸‹è³‡è¨Šï¼š

| æ¬„ä½ | è¨­å®šå€¼ | èªªæ˜Ž |
| :--- | :--- | :--- |
| **Template Name** | `Production-vLLM-Engine` | è¾¨è­˜ç”¨çš„åç¨± |
| **Container Image** | `vllm/vllm-openai:latest` | ä½¿ç”¨ vLLM å®˜æ–¹æ˜ åƒæª” |
| **Container Disk** | `20 GB` | å­˜æ”¾æ¨¡åž‹æ‰€éœ€çš„ç©ºé–“ |
| **Exposed Port** | `8000` | å°å¤–é–‹æ”¾çš„ API Port |

4. **ç’°å¢ƒè®Šæ•¸ (Environment Variables)** - **æœ€é‡è¦çš„éƒ¨åˆ†ï¼**
   è«‹é»žæ“Š "Add Variable" æ–°å¢žä»¥ä¸‹è®Šæ•¸ï¼š

   - `MODEL`: `TheBloke/Mistral-7B-Instruct-v0.2-AWQ`
     *(é€™æ˜¯æ¨¡åž‹åœ¨ HuggingFace ä¸Šçš„ IDï¼Œé¸ç”¨ AWQ é‡åŒ–ç‰ˆå¯å¤§å¹…æå‡é€Ÿåº¦ä¸¦é™ä½Žé¡¯å­˜éœ€æ±‚)*
   - `SERVED_MODEL_NAME`: `mistral`
     *(é€™æ˜¯ä¹‹å¾Œ API å‘¼å«æ™‚çš„ "model" åƒæ•¸åç¨±ï¼Œå»ºè­°ç°¡å–®å¥½è¨˜)*
   - `HF_TOKEN`: `(æ‚¨çš„ HuggingFace Token)`
     *(å¦‚æžœæ‚¨æ”¹ç”¨ Llama 3 ç­‰éœ€è¦æ¬Šé™çš„æ¨¡åž‹ï¼Œæ‰éœ€è¦å¡«å¯«æ­¤æ¬„ä½)*

5. é»žæ“Š **Save Template**ã€‚

---

## æ­¥é©ŸäºŒï¼šéƒ¨ç½²ç«¯é»ž (Deploy Endpoint)

1. å›žåˆ° **Serverless** é é¢ï¼Œé»žé¸ **New Endpoint**ã€‚
2. é¸æ“‡å‰›å‰›å»ºç«‹çš„ `Production-vLLM-Engine` æ¨¡æ¿ã€‚
3. **GPU é¸æ“‡**:
   - æŽ¨è–¦: **RTX 3090** æˆ– **RTX 4090** (æ€§åƒ¹æ¯”æœ€é«˜ï¼Œè·‘ 7B æ¨¡åž‹ç¶½ç¶½æœ‰é¤˜)ã€‚
   - ä¸æŽ¨è–¦: A100 (è·‘ 7B å¤ªæµªè²»éŒ¢äº†)ã€‚
4. **é€²éšŽè¨­å®š (Configuration)**:
   - **Min Workers**: `0` (çœéŒ¢æ¨¡å¼) æˆ– `1` (é«˜æ•ˆèƒ½æ¨¡å¼ï¼Œéš¨æ™‚å¾…å‘½)ã€‚
   - **Max Workers**: `5` (æ ¹æ“šæ‚¨çš„ç”¨æˆ¶æ•¸é‡èª¿æ•´ï¼Œæ¯å¢žåŠ ä¸€å€‹ Worker å°±å¤šä¸€å€‹ GPU å¹«å¿™è™•ç†)ã€‚
   - **Idle Timeout**: `5` (é–’ç½®å¹¾ç§’å¾Œé—œé–‰ Workerï¼Œå»ºè­°è¨­çŸ­ä¸€é»žçœéŒ¢)ã€‚
5. é»žæ“Š **Deploy**ã€‚

---

## æ­¥é©Ÿä¸‰ï¼šé€£æŽ¥åˆ°æ‡‰ç”¨ç¨‹å¼

1. ç­‰å¾… Endpoint ç‹€æ…‹è®Šç‚º `Running` (ç¬¬ä¸€æ¬¡éœ€è¦ä¸‹è¼‰æ¨¡åž‹ï¼Œç´„ 3-5 åˆ†é˜)ã€‚
2. é»žé€² Endpointï¼Œæ‚¨æœƒçœ‹åˆ°ï¼š
   - **Endpoint ID**: (ä¾‹å¦‚ `v8jom3acy6vy0s`)
   - **API Key**: é»žæ“Šä¸‹æ–¹çš„ "Settings" æˆ–æ˜¯å³ä¸Šè§’çš„å¸³æˆ¶è¨­å®šå–å¾—ã€‚
3. **API URL æ ¼å¼**:
   `https://api.runpod.ai/v2/[Endpoint_ID]/openai/v1`

---

## ðŸ’¡ æ‡‰ç”¨ç¨‹å¼è¨­å®š (GeminiService.ts)

å°‡å–å¾—çš„è³‡æ–™å¡«å…¥æ‚¨çš„ `DEFAULT_TEXT_SETTINGS`ï¼š

```typescript
const DEFAULT_TEXT_SETTINGS = {
    provider: 'runpod',
    runpodBaseUrl: 'https://api.runpod.ai/v2/v8jom3acy6vy0s/openai/v1', // æ›æˆæ‚¨çš„ ID
    runpodApiKey: 'rpa_xxxxxxxxxxxxxxxxxxxxxxxx', // æ›æˆæ‚¨çš„ Key
    runpodModelName: 'mistral' // å¿…é ˆå°æ‡‰æ¨¡æ¿ä¸­çš„ SERVED_MODEL_NAME
};
```

---

## â“ å¸¸è¦‹å•é¡Œ (Troubleshooting)

- **Q: ç‚ºä»€éº¼ä¸€ç›´è½‰åœˆåœˆæ²’åæ‡‰ï¼Ÿ**
  - A: æª¢æŸ¥ RunPod çš„ **Logs**ã€‚å¦‚æžœæ˜¯ `OOM (Out Of Memory)`ï¼Œä»£è¡¨é¡¯å­˜ä¸å¤ ï¼Œè«‹æ›é¡¯å­˜æ›´å¤§çš„ GPU (å¦‚ A6000) æˆ–æ›å°ä¸€é»žçš„æ¨¡åž‹ (AWQ)ã€‚
- **Q: è²»ç”¨å¦‚ä½•è¨ˆç®—ï¼Ÿ**
  - A: RunPod Serverless æ˜¯ "æŒ‰ç§’è¨ˆè²»"ã€‚GPU åªæœ‰åœ¨è™•ç†è«‹æ±‚æ™‚æ‰æ”¶è²» (åŠ ä¸Šå†·å•Ÿå‹•æ™‚é–“)ã€‚å¦‚æžœè¨­ Min Workers > 0ï¼Œé–’ç½®æ™‚ä¹Ÿæœƒæ”¶è²»ã€‚
